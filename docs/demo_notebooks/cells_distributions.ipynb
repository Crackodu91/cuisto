{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook shows how to load data exported from QuPath, compute metrics and display them, according to the configuration file. This is meant for a single-animal.\n",
    "\n",
    "There are some conventions that need to be met in the QuPath project so that the measurements are usable with `histoquant`:\n",
    "+ Objects' classifications must be derived, eg. be in the form \"something: else\". The primary classification (\"something\") will be refered to \"object_type\" and the secondary classification (\"else\") to \"channel\" in the configuration file.\n",
    "+ Only one \"object_type\" can be processed at once, but supports any numbers of channels.\n",
    "+ Annotations (brain regions) must have properly formatted measurements. For punctual objects, it would be the count. Run the \"add_regions_count.groovy\" script to add them. The measurements names must be in the form \"something: else name\", for instance, \"something: else Count\". \"name\" is refered to \"base_measurement\" in the configuration file.\n",
    "\n",
    "You should copy this notebook, the configuration file and the atlas-related configuration files (blacklist and fusion) elsewhere and edit them according to your need.\n",
    "\n",
    "The data was generated from QuPath with stardist cell detection on toy data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import histoquant as hq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Full path to your configuration file, edited according to your need beforehand\n",
    "config_file = \"../../resources/demo_config_cells.toml\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# - Files\n",
    "# animal identifier\n",
    "animal = \"animalid0\"\n",
    "# set the full path to the annotations tsv file from QuPath\n",
    "annotations_file = \"../../resources/cells_measurements_annotations.tsv\"\n",
    "# set the full path to the detections tsv file from QuPath\n",
    "detections_file = \"../../resources/cells_measurements_detections.tsv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get configuration\n",
    "cfg = hq.config.Config(config_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read data\n",
    "df_annotations = pd.read_csv(annotations_file, index_col=\"Object ID\", sep=\"\\t\")\n",
    "df_detections = pd.read_csv(detections_file, index_col=\"Object ID\", sep=\"\\t\")\n",
    "\n",
    "# remove annotations that are not brain regions\n",
    "df_annotations = df_annotations[df_annotations[\"Classification\"] != \"Region*\"]\n",
    "df_annotations = df_annotations[df_annotations[\"ROI\"] != \"Rectangle\"]\n",
    "\n",
    "# convert atlas coordinates from mm to microns\n",
    "df_detections[[\"Atlas_X\", \"Atlas_Y\", \"Atlas_Z\"]] = df_detections[\n",
    "    [\"Atlas_X\", \"Atlas_Y\", \"Atlas_Z\"]\n",
    "].multiply(1000)\n",
    "\n",
    "# have a look\n",
    "display(df_annotations.head())\n",
    "display(df_detections.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get distributions per regions, spatial distributions and coordinates\n",
    "df_regions, dfs_distributions, df_coordinates = hq.process.process_animal(\n",
    "    animal, df_annotations, df_detections, cfg, compute_distributions=True\n",
    ")\n",
    "\n",
    "# have a look\n",
    "display(df_regions.head())\n",
    "display(df_coordinates.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot distributions per regions\n",
    "figs_regions = hq.display.plot_regions(df_regions, cfg)\n",
    "# specify which regions to plot\n",
    "# figs_regions = hq.display.plot_regions(df_regions, cfg, names_list=[\"GRN\", \"IRN\", \"MDRNv\"])\n",
    "\n",
    "# save as svg\n",
    "# figs_regions[0].savefig(r\"C:\\Users\\glegoc\\Downloads\\regions_count.svg\")\n",
    "# figs_regions[1].savefig(r\"C:\\Users\\glegoc\\Downloads\\regions_density.svg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot 1D distributions\n",
    "fig_distrib = hq.display.plot_1D_distributions(\n",
    "    dfs_distributions, cfg, df_coordinates=df_coordinates\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If there were several `animal` in the measurement file, it would be displayed as mean +/- sem instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot heatmap (all types of cells pooled)\n",
    "fig_heatmap = hq.display.plot_2D_distributions(df_coordinates, cfg)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hq",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
